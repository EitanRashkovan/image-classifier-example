{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recognizing handwritten signatures\n",
    "### We hope to distinguish between real and forged handwritten signatures."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# import required modules, packages\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "from pathlib import Path\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# import datasets, classifiers, performance metrics\r\n",
    "from sklearn import datasets, svm, metrics\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: we will be using square shape (200, 200) to resize for now\r\n",
    "\\\r\n",
    "There are a lot of subfolders so I'm not sure how to go through multiple datasets yet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# accessing the dataset\r\n",
    "from PIL import Image, ImageOps\r\n",
    "\r\n",
    "# test run with sample_Signature\r\n",
    "p = Path(\"sample_Signature/\")\r\n",
    "dirs = p.glob(\"*\")\r\n",
    "labels_dict = {'forge':0, 'genuin':1}\r\n",
    "\r\n",
    "image_data = []\r\n",
    "labels = []\r\n",
    "\r\n",
    "for folder_dir in dirs:\r\n",
    "    label = str(folder_dir).split(\"\\\\\")[-1][:-1]\r\n",
    "\r\n",
    "    for img_path in folder_dir.glob(\"*.png\"):\r\n",
    "        # reading/opens each image\r\n",
    "        img = Image.open(img_path)\r\n",
    "        if 'L' in img.getbands():  # image is black-and-white, colorize it\r\n",
    "            img = ImageOps.colorize(img, black=\"blue\", white=\"white\")\r\n",
    "        \r\n",
    "        # resize\r\n",
    "        img_new = img.resize((200,200))\r\n",
    "        # convert image to numpy array\r\n",
    "        img_array = np.asarray(img_new)\r\n",
    "        # append each image array to image_data list\r\n",
    "        image_data.append(img_array)\r\n",
    "        # match the label to corresponding image\r\n",
    "        labels.append(labels_dict[label])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'genuin'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11140/3116704910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mimage_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# match the label to corresponding image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'genuin'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# both print statements should return the same value, one label for each image\r\n",
    "print(len(image_data))\r\n",
    "print(len(labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Converting image data into numpy array\r\n",
    "image_data = np.array(image_data, dtype = 'float32')/255.0\r\n",
    "labels = np.array(labels)\r\n",
    "\r\n",
    "print(image_data.shape, labels.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# visualize data\r\n",
    "def drawImg(img):\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "    plt.imshow(img)\r\n",
    "    plt.axis('off')\r\n",
    "    plt.show()\r\n",
    "    return\r\n",
    "\r\n",
    "# 10 example visualizations\r\n",
    "for i in range(10):\r\n",
    "    drawImg(image_data[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification\n",
    "modified based on scikit-learn 'recognizing handwritten digits' example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\r\n",
    "\r\n",
    "# OG example used 'digits.images' and 'digits.target' instead of 'image_data' and 'labels'\r\n",
    "for ax, image, label in zip(axes, image_data, labels):\r\n",
    "    ax.set_axis_off()\r\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\r\n",
    "    ax.set_title('Training: %i' % label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to use a classifier, first need to flatten images, convert to grayscale\r\n",
    "\r\n",
    "# flatten images\r\n",
    "n_samples = len(image_data)\r\n",
    "data = image_data.reshape((n_samples, -1))\r\n",
    "\r\n",
    "# create a classifier: support vector classifier\r\n",
    "clf = svm.SVC(gamma = 0.001)\r\n",
    "\r\n",
    "# split data into 50% train and 50% test subsets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    data, labels, test_size =0.5, shuffle = False)\r\n",
    "\r\n",
    "# learn the signatures on the train subset\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "# predict the signature (forge or real) on the test subset\r\n",
    "predicted = clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# take samples to predict and visualize\r\n",
    "_, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\r\n",
    "for ax, image, prediction in zip(axes, X_test, predicted):\r\n",
    "    ax.set_axis_off()\r\n",
    "    image = image.reshape(200, 100)\r\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\r\n",
    "    ax.set_title(f'Prediction: {prediction}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Seralization\n",
    "### loading the model into memory\n",
    "\\\n",
    "follows the example website Jason gave"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.externals import joblib\r\n",
    "joblib.dump(lr, 'model.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deserialization\n",
    "### loading the model back into your workspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr = joblib.load('model.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c082f1928081d7118f23db1cd88e0b6711ebf62990069b8eb954c11e1102cda"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}